{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d94fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# LLM Models Cost-Efficiency Analysis\\n\",\n",
    "    \"## Professional Analysis of Different Language Models Performance and Pricing\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Author:** Data Analysis Team  \\n\",\n",
    "    \"**Date:** 2024  \\n\",\n",
    "    \"**Objective:** Compare cost-efficiency metrics across different LLM providers\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Import Libraries and Load Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"from IPython.display import display, Markdown\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set style for better-looking plots\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8-darkgrid')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\\n\",\n",
    "    \"%matplotlib inline\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set figure size default\\n\",\n",
    "    \"plt.rcParams['figure.figsize'] = (12, 6)\\n\",\n",
    "    \"plt.rcParams['font.size'] = 10\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"‚úì Libraries imported successfully\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load dataset\\n\",\n",
    "    \"df = pd.read_csv('llm_models_data.csv')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Dataset loaded successfully!\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nDataset shape: {df.shape[0]} rows √ó {df.shape[1]} columns\\\")\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"display(df)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Data Exploration and Quality Check\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Data info\\n\",\n",
    "    \"print(\\\"Dataset Information:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"df.info()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"Missing Values:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"print(df.isnull().sum())\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"Data Types:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"print(df.dtypes)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Descriptive Statistics\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Statistical summary\\n\",\n",
    "    \"print(\\\"Descriptive Statistics:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"display(df.describe().round(4))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Additional statistics\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"Additional Metrics:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"print(f\\\"Total words processed: {df['words'].sum():,}\\\")\\n\",\n",
    "    \"print(f\\\"Total tokens processed: {df['tokens'].sum():,}\\\")\\n\",\n",
    "    \"print(f\\\"Total cost (USD): ${df['cost_usd'].sum():.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Total cost (RUB): ‚ÇΩ{df['cost_rub'].sum():.2f}\\\")\\n\",\n",
    "    \"print(f\\\"Average cost per model (USD): ${df['cost_usd'].mean():.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Feature Engineering - Calculate Efficiency Metrics\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Calculate cost per word and cost per token\\n\",\n",
    "    \"df['cost_per_word_usd'] = df['cost_usd'] / df['words']\\n\",\n",
    "    \"df['cost_per_token_usd'] = df['cost_usd'] / df['tokens']\\n\",\n",
    "    \"df['tokens_per_word'] = df['tokens'] / df['words']\\n\",\n",
    "    \"df['cost_per_word_rub'] = df['cost_rub'] / df['words']\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Efficiency Metrics Calculated:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"display(df[['model', 'cost_per_word_usd', 'cost_per_token_usd', \\n\",\n",
    "    \"            'tokens_per_word']].round(6))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Ranking Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Rank models by cost efficiency\\n\",\n",
    "    \"print(\\\"üèÜ MODEL RANKINGS\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n1. Most Cost-Effective (Lowest Cost per Word):\\\")\\n\",\n",
    "    \"print(\\\"-\\\"*60)\\n\",\n",
    "    \"ranking_word = df[['model', 'cost_per_word_usd']].sort_values('cost_per_word_usd')\\n\",\n",
    "    \"for idx, (i, row) in enumerate(ranking_word.iterrows(), 1):\\n\",\n",
    "    \"    print(f\\\"   {idx}. {row['model']:<25} ${row['cost_per_word_usd']:.6f}/word\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n2. Most Cost-Effective (Lowest Cost per Token):\\\")\\n\",\n",
    "    \"print(\\\"-\\\"*60)\\n\",\n",
    "    \"ranking_token = df[['model', 'cost_per_token_usd']].sort_values('cost_per_token_usd')\\n\",\n",
    "    \"for idx, (i, row) in enumerate(ranking_token.iterrows(), 1):\\n\",\n",
    "    \"    print(f\\\"   {idx}. {row['model']:<25} ${row['cost_per_token_usd']:.6f}/token\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n3. Most Token-Efficient (Lowest Tokens per Word):\\\")\\n\",\n",
    "    \"print(\\\"-\\\"*60)\\n\",\n",
    "    \"ranking_efficiency = df[['model', 'tokens_per_word']].sort_values('tokens_per_word')\\n\",\n",
    "    \"for idx, (i, row) in enumerate(ranking_efficiency.iterrows(), 1):\\n\",\n",
    "    \"    print(f\\\"   {idx}. {row['model']:<25} {row['tokens_per_word']:.2f} tokens/word\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Visualization - Cost Comparison\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create a comprehensive visualization\\n\",\n",
    "    \"fig, axes = plt.subplots(2, 2, figsize=(16, 12))\\n\",\n",
    "    \"fig.suptitle('LLM Models: Comprehensive Cost Analysis', fontsize=16, fontweight='bold', y=1.00)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 1. Total Cost Comparison (USD)\\n\",\n",
    "    \"ax1 = axes[0, 0]\\n\",\n",
    "    \"bars1 = ax1.bar(df['model'], df['cost_usd'], color=sns.color_palette(\\\"viridis\\\", len(df)), \\n\",\n",
    "    \"                edgecolor='black', linewidth=1.2)\\n\",\n",
    "    \"ax1.set_title('Total Cost per Model (USD)', fontsize=12, fontweight='bold', pad=10)\\n\",\n",
    "    \"ax1.set_xlabel('Model', fontsize=10, fontweight='bold')\\n\",\n",
    "    \"ax1.set_ylabel('Cost (USD)', fontsize=10, fontweight='bold')\\n\",\n",
    "    \"ax1.tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"ax1.grid(axis='y', alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add value labels on bars\\n\",\n",
    "    \"for bar in bars1:\\n\",\n",
    "    \"    height = bar.get_height()\\n\",\n",
    "    \"    ax1.text(bar.get_x() + bar.get_width()/2., height,\\n\",\n",
    "    \"             f'${height:.4f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 2. Cost per Word Comparison\\n\",\n",
    "    \"ax2 = axes[0, 1]\\n\",\n",
    "    \"bars2 = ax2.bar(df['model'], df['cost_per_word_usd'], color=sns.color_palette(\\\"rocket\\\", len(df)),\\n\",\n",
    "    \"                edgecolor='black', linewidth=1.2)\\n\",\n",
    "    \"ax2.set_title('Cost Efficiency: Cost per Word (USD)', fontsize=12, fontweight='bold', pad=10)\\n\",\n",
    "    \"ax2.set_xlabel('Model', fontsize=10, fontweight='bold')\\n\",\n",
    "    \"ax2.set_ylabel('Cost per Word (USD)', fontsize=10, fontweight='bold')\\n\",\n",
    "    \"ax2.tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"ax2.grid(axis='y', alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"for bar in bars2:\\n\",\n",
    "    \"    height = bar.get_height()\\n\",\n",
    "    \"    ax2.text(bar.get_x() + bar.get_width()/2., height,\\n\",\n",
    "    \"             f'${height:.6f}', ha='center', va='bottom', fontsize=8, fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 3. Words vs Tokens Scatter Plot\\n\",\n",
    "    \"ax3 = axes[1, 0]\\n\",\n",
    "    \"scatter = ax3.scatter(df['words'], df['tokens'], s=df['cost_usd']*10000, \\n\",\n",
    "    \"                      c=df['cost_usd'], cmap='coolwarm', alpha=0.7, \\n\",\n",
    "    \"                      edgecolors='black', linewidth=2)\\n\",\n",
    "    \"ax3.set_title('Words vs Tokens (bubble size = cost)', fontsize=12, fontweight='bold', pad=10)\\n\",\n",
    "    \"ax3.set_xlabel('Words', fontsize=10, fontweight='bold')\\n\",\n",
    "    \"ax3.set_ylabel('Tokens', fontsize=10, fontweight='bold')\\n\",\n",
    "    \"ax3.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add model labels to scatter points\\n\",\n",
    "    \"for idx, row in df.iterrows():\\n\",\n",
    "    \"    ax3.annotate(row['model'], (row['words'], row['tokens']), \\n\",\n",
    "    \"                fontsize=8, ha='center', va='bottom')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add colorbar\\n\",\n",
    "    \"cbar = plt.colorbar(scatter, ax=ax3)\\n\",\n",
    "    \"cbar.set_label('Cost (USD)', fontsize=9, fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 4. Tokens per Word Ratio\\n\",\n",
    "    \"ax4 = axes[1, 1]\\n\",\n",
    "    \"bars4 = ax4.barh(df['model'], df['tokens_per_word'], color=sns.color_palette(\\\"mako\\\", len(df)),\\n\",\n",
    "    \"                 edgecolor='black', linewidth=1.2)\\n\",\n",
    "    \"ax4.set_title('Token Efficiency: Tokens per Word Ratio', fontsize=12, fontweight='bold', pad=10)\\n\",\n",
    "    \"ax4.set_xlabel('Tokens per Word', fontsize=10, fontweight='bold')\\n\",\n",
    "    \"ax4.set_ylabel('Model', fontsize=10, fontweight='bold')\\n\",\n",
    "    \"ax4.grid(axis='x', alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"for bar in bars4:\\n\",\n",
    "    \"    width = bar.get_width()\\n\",\n",
    "    \"    ax4.text(width, bar.get_y() + bar.get_height()/2.,\\n\",\n",
    "    \"             f'{width:.2f}', ha='left', va='center', fontsize=9, fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('llm_cost_analysis.png', dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"‚úì Visualization saved as 'llm_cost_analysis.png'\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Detailed Cost Breakdown Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create pie charts for cost distribution\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 2, figsize=(16, 6))\\n\",\n",
    "    \"fig.suptitle('Cost Distribution Analysis', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# USD Distribution\\n\",\n",
    "    \"colors = sns.color_palette('pastel')[0:len(df)]\\n\",\n",
    "    \"explode = [0.05 if x == df['cost_usd'].max() else 0 for x in df['cost_usd']]\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[0].pie(df['cost_usd'], labels=df['model'], autopct='%1.1f%%',\\n\",\n",
    "    \"            startangle=90, colors=colors, explode=explode,\\n\",\n",
    "    \"            textprops={'fontsize': 10, 'fontweight': 'bold'})\\n\",\n",
    "    \"axes[0].set_title('Cost Distribution (USD)', fontsize=12, fontweight='bold', pad=20)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# RUB Distribution\\n\",\n",
    "    \"explode_rub = [0.05 if x == df['cost_rub'].max() else 0 for x in df['cost_rub']]\\n\",\n",
    "    \"axes[1].pie(df['cost_rub'], labels=df['model'], autopct='%1.1f%%',\\n\",\n",
    "    \"            startangle=90, colors=colors, explode=explode_rub,\\n\",\n",
    "    \"            textprops={'fontsize': 10, 'fontweight': 'bold'})\\n\",\n",
    "    \"axes[1].set_title('Cost Distribution (RUB)', fontsize=12, fontweight='bold', pad=20)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('cost_distribution.png', dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"‚úì Cost distribution chart saved as 'cost_distribution.png'\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Correlation Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Correlation heatmap\\n\",\n",
    "    \"plt.figure(figsize=(10, 8))\\n\",\n",
    "    \"correlation_cols = ['words', 'tokens', 'cost_usd', 'cost_rub', \\n\",\n",
    "    \"                    'cost_per_word_usd', 'cost_per_token_usd', 'tokens_per_word']\\n\",\n",
    "    \"correlation_matrix = df[correlation_cols].corr()\\n\",\n",
    "    \"\\n\",\n",
    "    \"sns.heatmap(correlation_matrix, annot=True, fmt='.3f', cmap='coolwarm', \\n\",\n",
    "    \"            center=0, square=True, linewidths=1, cbar_kws={\\\"shrink\\\": 0.8})\\n\",\n",
    "    \"plt.title('Correlation Matrix: LLM Metrics', fontsize=14, fontweight='bold', pad=20)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"‚úì Correlation heatmap saved as 'correlation_heatmap.png'\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"Key Correlations:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"print(f\\\"Words vs Tokens: {correlation_matrix.loc['words', 'tokens']:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"Words vs Cost (USD): {correlation_matrix.loc['words', 'cost_usd']:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"Tokens vs Cost (USD): {correlation_matrix.loc['tokens', 'cost_usd']:.3f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Summary Report\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate comprehensive summary\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*80)\\n\",\n",
    "    \"print(\\\" \\\"*25 + \\\"üìä EXECUTIVE SUMMARY REPORT\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*80)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n1. MOST COST-EFFECTIVE MODEL:\\\")\\n\",\n",
    "    \"print(\\\"-\\\"*80)\\n\",\n",
    "    \"best_model = df.loc[df['cost_per_word_usd'].idxmin()]\\n\",\n",
    "    \"print(f\\\"   üèÜ {best_model['model'].upper()}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Cost per word: ${best_model['cost_per_word_usd']:.6f}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Cost per token: ${best_model['cost_per_token_usd']:.6f}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Total cost: ${best_model['cost_usd']:.4f} | ‚ÇΩ{best_model['cost_rub']:.2f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n2. MOST EXPENSIVE MODEL:\\\")\\n\",\n",
    "    \"print(\\\"-\\\"*80)\\n\",\n",
    "    \"expensive_model = df.loc[df['cost_per_word_usd'].idxmax()]\\n\",\n",
    "    \"print(f\\\"   üí∞ {expensive_model['model'].upper()}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Cost per word: ${expensive_model['cost_per_word_usd']:.6f}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Cost per token: ${expensive_model['cost_per_token_usd']:.6f}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Total cost: ${expensive_model['cost_usd']:.4f} | ‚ÇΩ{expensive_model['cost_rub']:.2f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n3. MOST TOKEN-EFFICIENT MODEL:\\\")\\n\",\n",
    "    \"print(\\\"-\\\"*80)\\n\",\n",
    "    \"efficient_model = df.loc[df['tokens_per_word'].idxmin()]\\n\",\n",
    "    \"print(f\\\"   ‚ö° {efficient_model['model'].upper()}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Tokens per word: {efficient_model['tokens_per_word']:.2f}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Total tokens: {efficient_model['tokens']:.0f}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Total words: {efficient_model['words']:.0f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n4. AGGREGATE STATISTICS:\\\")\\n\",\n",
    "    \"print(\\\"-\\\"*80)\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Total models analyzed: {len(df)}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Total words processed: {df['words'].sum():,.0f}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Total tokens processed: {df['tokens'].sum():,.0f}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Total cost: ${df['cost_usd'].sum():.4f} USD | ‚ÇΩ{df['cost_rub'].sum():.2f} RUB\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Average cost per word: ${df['cost_per_word_usd'].mean():.6f}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Average cost per token: ${df['cost_per_token_usd'].mean():.6f}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Average tokens per word: {df['tokens_per_word'].mean():.2f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n5. COST EFFICIENCY RATIO:\\\")\\n\",\n",
    "    \"print(\\\"-\\\"*80)\\n\",\n",
    "    \"cost_ratio = expensive_model['cost_per_word_usd'] / best_model['cost_per_word_usd']\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Most expensive model is {cost_ratio:.1f}x more expensive than cheapest\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Price spread: ${df['cost_per_word_usd'].std():.6f} (standard deviation)\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*80)\\n\",\n",
    "    \"print(\\\" \\\"*25 + \\\"‚úì ANALYSIS COMPLETE\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*80)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 10. Export Results\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Export enhanced dataset with calculated metrics\\n\",\n",
    "    \"output_df = df[['model', 'words', 'tokens', 'cost_usd', 'cost_rub',\\n\",\n",
    "    \"                'cost_per_word_usd', 'cost_per_token_usd', 'tokens_per_word']].round(6)\\n\",\n",
    "    \"\\n\",\n",
    "    \"output_df.to_csv('llm_analysis_results.csv', index=False)\\n\",\n",
    "    \"output_df.to_excel('llm_analysis_results.xlsx', index=False, engine='openpyxl')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"‚úì Results exported to:\\\")\\n\",\n",
    "    \"print(\\\"  ‚Ä¢ llm_analysis_results.csv\\\")\\n\",\n",
    "    \"print(\\\"  ‚Ä¢ llm_analysis_results.xlsx\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display final dataframe\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*80)\\n\",\n",
    "    \"print(\\\"Final Dataset with Calculated Metrics:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*80)\\n\",\n",
    "    \"display(output_df)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 11. Key Insights & Recommendations\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"display(Markdown(\\\"\\\"\\\"\\n\",\n",
    "    \"## üéØ Key Insights:\\n\",\n",
    "    \"\\n\",\n",
    "    \"### üí° Cost Efficiency:\\n\",\n",
    "    \"- **Gemini 1.5 Pro** offers the best cost per word efficiency\\n\",\n",
    "    \"- **YandexGPT 5.1 Pro** is the most expensive option\\n\",\n",
    "    \"- There's significant price variation between providers (up to 100x difference)\\n\",\n",
    "    \"\\n\",\n",
    "    \"### üìà Token Utilization:\\n\",\n",
    "    \"- Different models have varying tokenization strategies\\n\",\n",
    "    \"- More tokens per word doesn't necessarily mean higher cost\\n\",\n",
    "    \"- Token efficiency should be considered alongside pricing\\n\",\n",
    "    \"\\n\",\n",
    "    \"### üíº Business Recommendations:\\n\",\n",
    "    \"1. **For Budget-Conscious Projects**: Use Gemini 1.5 Pro or Qwen Plus\\n\",\n",
    "    \"2. **For High Volume Processing**: Consider cost per token carefully\\n\",\n",
    "    \"3. **For Specialized Tasks**: Evaluate quality vs. cost trade-offs\\n\",\n",
    "    \"4. **ROI Optimization**: Monitor cost per word metrics continuously\\n\",\n",
    "    \"\\n\",\n",
    "    \"### üîç Further Analysis Needed:\\n\",\n",
    "    \"- Output quality comparison\\n\",\n",
    "    \"- Response time analysis\\n\",\n",
    "    \"- Use-case specific performance\\n\",\n",
    "    \"- Long-term pricing stability\\n\",\n",
    "    \"\\\"\\\"\\\"))\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
